{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats // 2 + 1  # todo even vrsos odd\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats * 32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i == 0 else rnn_dim * 2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i == 0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim * 2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2)  # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from jiwer import wer\n",
    "import Model\n",
    "import Utils\n",
    "from ASR import WB\n",
    "\n",
    "\n",
    "def train(model, device, batch_iterator, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(batch_iterator)\n",
    "    for batch_idx, _data in enumerate(batch_iterator):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data\n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)  # using log_softmax instead of softmax for numerical stability\n",
    "        output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, torch.from_numpy(input_lengths), torch.from_numpy(label_lengths))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if batch_idx % 50 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                       100. * batch_idx / data_len, loss.item()))\n",
    "            if WB:\n",
    "                wandb.log({\"train_loss\": loss.item()})\n",
    "                decoded_preds, decoded_targets = Utils.greedy_decoder(output.transpose(0, 1), labels,\n",
    "                                                                           label_lengths)\n",
    "                wer_sum = 0\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    wer_sum += wer(decoded_targets[j], decoded_preds[j])\n",
    "\n",
    "                wandb.log({\"train_wer\": wer_sum / len(decoded_preds)})\n",
    "\n",
    "\n",
    "def validation(model, device, val_loader, criterion, epoch):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_wer = []\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(val_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, torch.from_numpy(input_lengths), torch.from_numpy(label_lengths))\n",
    "            val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = Utils.greedy_decoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                val_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_wer = sum(val_wer) / len(val_wer)\n",
    "    # experiment.log_metric('val_loss', val_loss, step=iter_meter.get())\n",
    "    # experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print(\n",
    "        'val set: Average loss: {:.4f}, Average WER: {:.4f}\\n'.format(val_loss, avg_wer))\n",
    "\n",
    "    # print a sample of the val data and decoded predictions against the true labels\n",
    "    if epoch % 10 == 0:\n",
    "        print('Ground Truth -> Decoded Prediction')\n",
    "        for i in range(10):\n",
    "            print('{} -> {}'.format(decoded_targets[i], decoded_preds[i]))\n",
    "\n",
    "    if WB:\n",
    "        wandb.log({\"val_loss\": val_loss})\n",
    "        wandb.log({\"val_wer\": avg_wer})\n",
    "\n",
    "\n",
    "def train_and_validation(hparams, batch_iterators):\n",
    "    train_loader = batch_iterators[0]\n",
    "    val_loader = batch_iterators[1]\n",
    "    epochs = hparams['epochs']\n",
    "\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = Model.SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'],\n",
    "                                              steps_per_epoch=len(train_loader),  # todo: check if this is correct\n",
    "                                              epochs=hparams['epochs'],\n",
    "                                              anneal_strategy='linear')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        validation(model, device, val_loader, criterion, epoch)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')\n",
    "\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "\n",
    "def greedy_decoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    \"\"\"\n",
    "    Greedy Decoder. Decodes the output of the network by picking the label with the highest probability at each time step.\n",
    "    \"\"\"\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j - 1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from Utils import TextTransform\n",
    "from HyperParameters import hparams\n",
    "\n",
    "\n",
    "class BatchIterator:\n",
    "    def __init__(self, x, y, input_lengths, label_lengths, batch_size, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.input_lengths = input_lengths\n",
    "        self.label_lengths = label_lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = len(x)\n",
    "        self.num_batches = (self.num_samples + batch_size - 1) // batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.current_batch = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.random.permutation(self.num_samples)\n",
    "            self.x = self.x[indices]\n",
    "            self.y = self.y[indices]\n",
    "            self.input_lengths = np.asarray(self.input_lengths)[indices]\n",
    "            self.label_lengths = np.asarray(self.label_lengths)[indices]\n",
    "        self.current_batch = 0\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch < self.num_batches:\n",
    "            start_idx = self.current_batch * self.batch_size\n",
    "            end_idx = min((self.current_batch + 1) * self.batch_size, self.num_samples)\n",
    "\n",
    "            batch_x = self.x[start_idx:end_idx]\n",
    "            batch_y = self.y[start_idx:end_idx]\n",
    "            batch_input_lengths = self.input_lengths[start_idx:end_idx]\n",
    "            batch_label_lengths = self.label_lengths[start_idx:end_idx]\n",
    "\n",
    "            self.current_batch += 1\n",
    "\n",
    "            return batch_x, batch_y, batch_input_lengths, batch_label_lengths\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "def load_wavs_data(load_again=False, save=False,\n",
    "                   path=r\".\\an4\"):\n",
    "    text_transform = TextTransform()\n",
    "\n",
    "    if load_again:\n",
    "        all_spectrogram = torch.load(\"data/all_spectrogram.pt\")\n",
    "        all_labels = torch.load(\"data/all_labels.pt\")\n",
    "        all_input_lengths = torch.load(\"data/all_input_lengths.pt\")\n",
    "        all_label_lengths = torch.load(\"data/all_label_lengths.pt\")\n",
    "        return all_spectrogram, all_labels, all_input_lengths, all_label_lengths\n",
    "\n",
    "    valid_file = [\"test\", \"train\", \"val\"]\n",
    "    all_spectrogram = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_labels = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_input_lengths = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_label_lengths = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    for dir in os.listdir(path):\n",
    "        if dir in valid_file:\n",
    "            spectrogram = []\n",
    "            labels = []\n",
    "            input_lengths = []\n",
    "            label_lengths = []\n",
    "            for root2, dirs2, files2 in os.walk(os.path.join(path, dir)):\n",
    "                for file in files2:\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        # change suffix to wav\n",
    "                        wav = file.replace(\".txt\", \".wav\")\n",
    "                        # print(os.path.join(root2, file))\n",
    "                        # change last dir to wav instead of txt\n",
    "                        root2_wav = root2.replace(\"txt\", \"wav\")\n",
    "\n",
    "                        # load wav:\n",
    "                        waveform, sample_rate = torchaudio.load(os.path.join(root2_wav, wav))\n",
    "                        # mfcc:\n",
    "                        mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=13)(waveform)\n",
    "                        mfcc = mfcc.squeeze(0)\n",
    "                        mfcc = mfcc.transpose(0, 1)\n",
    "                        # add mfcc to y:\n",
    "                        spectrogram.append(mfcc)\n",
    "\n",
    "                        # load txt:\n",
    "                        with open(os.path.join(root2, file), 'r') as f:\n",
    "                            text = f.read()\n",
    "                            int_text = text_transform.text_to_int(text.lower())\n",
    "                        # add text to labels:\n",
    "                        label = torch.Tensor(int_text)\n",
    "                        labels.append(label)\n",
    "                        input_lengths.append(mfcc.shape[0] // 2)  # todo why divide by 2?\n",
    "                        label_lengths.append(len(label))\n",
    "                    # print(file)\n",
    "\n",
    "            # todo maybe the padding should be done for all the data together (train test and val)\n",
    "            spectrogram = nn.utils.rnn.pad_sequence(spectrogram, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "            labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "            all_spectrogram[dir] = spectrogram\n",
    "            all_labels[dir] = labels\n",
    "            all_input_lengths[dir] = input_lengths\n",
    "            all_label_lengths[dir] = label_lengths\n",
    "\n",
    "    if save:\n",
    "        torch.save(all_spectrogram, \"data/all_spectrogram.pt\")\n",
    "        torch.save(all_labels, \"data/all_labels.pt\")\n",
    "        torch.save(all_input_lengths, \"data/all_input_lengths.pt\")\n",
    "        torch.save(all_label_lengths, \"data/all_label_lengths.pt\")\n",
    "    return all_spectrogram, all_labels, all_input_lengths, all_label_lengths\n",
    "\n",
    "\n",
    "def get_batch_iterator(data_type, batch_size=hparams[\"batch_size\"]):\n",
    "    if data_type not in [\"test\", \"train\", \"val\"]:\n",
    "        raise ValueError(\"data_type must be one of [test, train, val]\")\n",
    "    all_spectrogram, all_labels, all_input_lengths, all_label_lengths = load_wavs_data(load_again=True, save=True)\n",
    "    return BatchIterator(all_spectrogram[data_type], all_labels[data_type],\n",
    "                         all_input_lengths[data_type], all_label_lengths[data_type], batch_size)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/86 (0%)]\tLoss: 21.304291\n",
      "Train Epoch: 1 [500/86 (58%)]\tLoss: 24.125551\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 12.1804, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 2 [0/86 (0%)]\tLoss: 10.630229\n",
      "Train Epoch: 2 [500/86 (58%)]\tLoss: 4.593483\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 3.5923, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 3 [0/86 (0%)]\tLoss: 3.419579\n",
      "Train Epoch: 3 [500/86 (58%)]\tLoss: 3.252816\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 3.3025, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 4 [0/86 (0%)]\tLoss: 3.477070\n",
      "Train Epoch: 4 [500/86 (58%)]\tLoss: 3.304673\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 3.1093, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 5 [0/86 (0%)]\tLoss: 3.081306\n",
      "Train Epoch: 5 [500/86 (58%)]\tLoss: 3.087465\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 3.0277, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 6 [0/86 (0%)]\tLoss: 3.054180\n",
      "Train Epoch: 6 [500/86 (58%)]\tLoss: 3.232636\n",
      "\n",
      "evaluating...\n",
      "val set: Average loss: 2.9881, Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 7 [0/86 (0%)]\tLoss: 3.249535\n"
     ]
    }
   ],
   "source": [
    "import TrainAndEvaluation\n",
    "import DataLoader\n",
    "import wandb\n",
    "from HyperParameters import hparams\n",
    "from HyperParameters import WB\n",
    "\n",
    "DESCRIPTION = 'initial work'\n",
    "RUN = 'Complex Model'\n",
    "\n",
    "\n",
    "def init_w_and_b():\n",
    "    epochs = hparams['epochs']\n",
    "    learning_rate = hparams['learning_rate']\n",
    "\n",
    "    if WB:\n",
    "        wandb.init(\n",
    "            # Set the project where this run will be logged\n",
    "            group=\"Complex Model initial work\",\n",
    "            project=\"ASR\",\n",
    "            # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "            name=f\"{DESCRIPTION}{RUN}_{hparams}_epochs\",\n",
    "            notes='checking if log is work properly',\n",
    "            # Track hyperparameters and run metadata\n",
    "            config={\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"architecture\": \"assembly\",\n",
    "                \"dataset\": \"AN4\",\n",
    "                \"epochs\": epochs,\n",
    "\n",
    "            })\n",
    "\n",
    "\n",
    "def main():\n",
    "    if WB:\n",
    "        wandb.login()\n",
    "        init_w_and_b()\n",
    "\n",
    "    train_batch_iterator = DataLoader.get_batch_iterator(\"train\", hparams[\"batch_size\"])\n",
    "    test_batch_iterator = DataLoader.get_batch_iterator(\"test\", hparams[\"batch_size\"])\n",
    "    val_batch_iterator = DataLoader.get_batch_iterator(\"val\", hparams[\"batch_size\"])\n",
    "    all_iterators = [train_batch_iterator, test_batch_iterator, val_batch_iterator]\n",
    "\n",
    "    TrainAndEvaluation.train_and_validation(hparams, all_iterators)\n",
    "\n",
    "    if WB:\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
