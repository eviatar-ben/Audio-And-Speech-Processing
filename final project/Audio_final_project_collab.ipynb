{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install wandb -qU\n",
    "# !pip install jiwer"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APFjEvX1XlOY",
    "outputId": "bd16c0e2-bc45-4b95-f0a9-2914b2266983",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.187994Z",
     "end_time": "2023-08-20T16:54:37.218816Z"
    }
   },
   "execution_count": 113,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !wandb login"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUMKH47Obbax",
    "outputId": "92599572-850a-4c15-ef79-9ed1aea12222",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.203630Z",
     "end_time": "2023-08-20T16:54:37.265943Z"
    }
   },
   "execution_count": 114,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !gdown \"1MiPqJDm6gX_ayXZJ2LHeUbG0UNZfNagF\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ho77aqVeeXPl",
    "outputId": "398aa6e0-67e9-4b5b-93e0-ad21de07485e",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.224760Z",
     "end_time": "2023-08-20T16:54:37.265943Z"
    }
   },
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !unzip an4.zip"
   ],
   "metadata": {
    "id": "XdRPjDyJsm66",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.234729Z",
     "end_time": "2023-08-20T16:54:37.265943Z"
    }
   },
   "execution_count": 116,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import wandb\n",
    "from jiwer import wer"
   ],
   "metadata": {
    "id": "Y9Iz7rIESdBF",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.250238Z",
     "end_time": "2023-08-20T16:54:37.265943Z"
    }
   },
   "execution_count": 117,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')\n",
    "\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "\n",
    "def greedy_decoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    \"\"\"\n",
    "    Greedy Decoder. Decodes the output of the network by picking the label with the highest probability at each time step.\n",
    "    \"\"\"\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j - 1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ],
   "metadata": {
    "id": "hihyyrkRWKQE",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.265943Z",
     "end_time": "2023-08-20T16:54:37.281528Z"
    }
   },
   "execution_count": 118,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "WB = False\n",
    "\n",
    "learning_rate = 5e-4\n",
    "batch_size = 10\n",
    "epochs = 200\n",
    "\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 3,\n",
    "    \"n_rnn_layers\": 2,\n",
    "    \"rnn_dim\": 128,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 13,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs\n",
    "}"
   ],
   "metadata": {
    "id": "OEy0y8HyW8Xt",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.286537Z",
     "end_time": "2023-08-20T16:54:37.313257Z"
    }
   },
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BatchIterator:\n",
    "    def __init__(self, x, y, input_lengths, label_lengths, batch_size, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.input_lengths = input_lengths\n",
    "        self.label_lengths = label_lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = len(x)\n",
    "        self.num_batches = (self.num_samples + batch_size - 1) // batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.current_batch = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.random.permutation(self.num_samples)\n",
    "            self.x = self.x[indices]\n",
    "            self.y = self.y[indices]\n",
    "            self.input_lengths = np.asarray(self.input_lengths)[indices]\n",
    "            self.label_lengths = np.asarray(self.label_lengths)[indices]\n",
    "        self.current_batch = 0\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch < self.num_batches:\n",
    "            start_idx = self.current_batch * self.batch_size\n",
    "            end_idx = min((self.current_batch + 1) * self.batch_size, self.num_samples)\n",
    "\n",
    "            batch_x = self.x[start_idx:end_idx]\n",
    "            batch_y = self.y[start_idx:end_idx]\n",
    "            batch_input_lengths = self.input_lengths[start_idx:end_idx]\n",
    "            batch_label_lengths = self.label_lengths[start_idx:end_idx]\n",
    "\n",
    "            self.current_batch += 1\n",
    "\n",
    "            return batch_x, batch_y, batch_input_lengths, batch_label_lengths\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "def load_wavs_data(load_again=False, save=False,\n",
    "                   path=r\".\\an4\"):\n",
    "    text_transform = TextTransform()\n",
    "\n",
    "    if load_again:\n",
    "        all_spectrogram = torch.load(\"data/all_spectrogram.pt\")\n",
    "        all_labels = torch.load(\"data/all_labels.pt\")\n",
    "        all_input_lengths = torch.load(\"data/all_input_lengths.pt\")\n",
    "        all_label_lengths = torch.load(\"data/all_label_lengths.pt\")\n",
    "        return all_spectrogram, all_labels, all_input_lengths, all_label_lengths\n",
    "\n",
    "    valid_file = [\"test\", \"train\", \"val\"]\n",
    "    all_spectrogram = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_labels = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_input_lengths = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    all_label_lengths = {\"test\": [], \"train\": [], \"val\": []}\n",
    "    for dir in os.listdir(path):\n",
    "        if dir in valid_file:\n",
    "            spectrogram = []\n",
    "            labels = []\n",
    "            input_lengths = []\n",
    "            label_lengths = []\n",
    "            for root2, dirs2, files2 in os.walk(os.path.join(path, dir)):\n",
    "                for file in files2:\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        # change suffix to wav\n",
    "                        wav = file.replace(\".txt\", \".wav\")\n",
    "                        # print(os.path.join(root2, file))\n",
    "                        # change last dir to wav instead of txt\n",
    "                        root2_wav = root2.replace(\"txt\", \"wav\")\n",
    "\n",
    "                        # load wav:\n",
    "                        waveform, sample_rate = torchaudio.load(os.path.join(root2_wav, wav))\n",
    "                        # mfcc:\n",
    "                        mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=13)(waveform)\n",
    "                        mfcc = mfcc.squeeze(0)\n",
    "                        mfcc = mfcc.transpose(0, 1)\n",
    "                        # add mfcc to y:\n",
    "                        spectrogram.append(mfcc)\n",
    "\n",
    "                        # load txt:\n",
    "                        with open(os.path.join(root2, file), 'r') as f:\n",
    "                            text = f.read()\n",
    "                            int_text = text_transform.text_to_int(text.lower())\n",
    "                        # add text to labels:\n",
    "                        label = torch.Tensor(int_text)\n",
    "                        labels.append(label)\n",
    "                        input_lengths.append(mfcc.shape[0] // 2)  # todo why divide by 2?\n",
    "                        label_lengths.append(len(label))\n",
    "                    # print(file)\n",
    "\n",
    "            # todo maybe the padding should be done for all the data together (train test and val)\n",
    "            spectrogram = nn.utils.rnn.pad_sequence(spectrogram, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "            labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "            all_spectrogram[dir] = spectrogram\n",
    "            all_labels[dir] = labels\n",
    "            all_input_lengths[dir] = input_lengths\n",
    "            all_label_lengths[dir] = label_lengths\n",
    "\n",
    "    if save:\n",
    "        torch.save(all_spectrogram, \"data/all_spectrogram.pt\")\n",
    "        torch.save(all_labels, \"data/all_labels.pt\")\n",
    "        torch.save(all_input_lengths, \"data/all_input_lengths.pt\")\n",
    "        torch.save(all_label_lengths, \"data/all_label_lengths.pt\")\n",
    "    return all_spectrogram, all_labels, all_input_lengths, all_label_lengths\n",
    "\n",
    "\n",
    "def get_batch_iterator(data_type, batch_size=hparams[\"batch_size\"]):\n",
    "    if data_type not in [\"test\", \"train\", \"val\"]:\n",
    "        raise ValueError(\"data_type must be one of [test, train, val]\")\n",
    "    all_spectrogram, all_labels, all_input_lengths, all_label_lengths = load_wavs_data(load_again=False, save=False)\n",
    "    return BatchIterator(all_spectrogram[data_type], all_labels[data_type],\n",
    "                         all_input_lengths[data_type], all_label_lengths[data_type], batch_size)"
   ],
   "metadata": {
    "id": "-S-kuwXvWOQA",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.297619Z",
     "end_time": "2023-08-20T16:54:37.328964Z"
    }
   },
   "execution_count": 120,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "XLkOVJdrSSaw",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.344505Z",
     "end_time": "2023-08-20T16:54:37.360134Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats // 2 + 1  # todo even vrsos odd\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats * 32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i == 0 else rnn_dim * 2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i == 0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim * 2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2)  # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, device, batch_iterator, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(batch_iterator)\n",
    "    for batch_idx, _data in enumerate(batch_iterator):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data\n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)  # using log_softmax instead of softmax for numerical stability\n",
    "        output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, torch.from_numpy(input_lengths), torch.from_numpy(label_lengths))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if batch_idx % 20 == 0 or batch_idx == data_len:\n",
    "            if WB:\n",
    "                wandb.log({\"train_loss\": loss.item()})\n",
    "                decoded_preds, decoded_targets = greedy_decoder(output.transpose(0, 1), labels,\n",
    "                                                                           label_lengths)\n",
    "                wer_sum = 0\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    wer_sum += wer(decoded_targets[j], decoded_preds[j])\n",
    "\n",
    "                wandb.log({\"train_wer\": wer_sum / len(decoded_preds)})\n",
    "\n",
    "\n",
    "def validation(model, device, val_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_wer = []\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(val_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1)  # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, torch.from_numpy(input_lengths), torch.from_numpy(label_lengths))\n",
    "            val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = greedy_decoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                val_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_wer = sum(val_wer) / len(val_wer)\n",
    "    # experiment.log_metric('val_loss', val_loss, step=iter_meter.get())\n",
    "    # experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "\n",
    "\n",
    "    # print a sample of the val data and decoded predictions against the true labels\n",
    "    if epoch % 20 == 0:\n",
    "        print(\n",
    "        'val set: Average loss: {:.4f}, Average WER: {:.4f}\\n'.format(val_loss, avg_wer))\n",
    "        print('Ground Truth -> Decoded Prediction')\n",
    "        for i in range(10):\n",
    "            print('{} -> {}'.format(decoded_targets[i], decoded_preds[i]))\n",
    "\n",
    "    if WB:\n",
    "        wandb.log({\"val_loss\": val_loss})\n",
    "        wandb.log({\"val_wer\": avg_wer})\n",
    "\n",
    "\n",
    "def train_and_validation(hparams, batch_iterators):\n",
    "    train_loader = batch_iterators[0]\n",
    "    val_loader = batch_iterators[1]\n",
    "    epochs = hparams['epochs']\n",
    "\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'],\n",
    "                                              steps_per_epoch=len(train_loader),  # todo: check if this is correct\n",
    "                                              epochs=hparams['epochs'],\n",
    "                                              anneal_strategy='linear')\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        validation(model, device, val_loader, criterion, epoch)"
   ],
   "metadata": {
    "id": "TM4DxKfZSpml",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.360134Z",
     "end_time": "2023-08-20T16:54:37.375754Z"
    }
   },
   "execution_count": 122,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DESCRIPTION = 'initial work'\n",
    "RUN = 'Complex Model'\n",
    "\n",
    "\n",
    "def init_w_and_b():\n",
    "    epochs = hparams['epochs']\n",
    "    learning_rate = hparams['learning_rate']\n",
    "\n",
    "    if WB:\n",
    "        wandb.init(\n",
    "            # Set the project where this run will be logged\n",
    "            group=\"Complex Model initial work\",\n",
    "            project=\"ASR\",\n",
    "            # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "            name=f\"{DESCRIPTION}{RUN}_{hparams}_epochs\",\n",
    "            notes='checking if log is work properly',\n",
    "            # Track hyperparameters and run metadata\n",
    "            config={\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"architecture\": \"assembly\",\n",
    "                \"dataset\": \"AN4\",\n",
    "                \"epochs\": epochs,\n",
    "\n",
    "            })\n",
    "\n",
    "\n",
    "def main():\n",
    "    if WB:\n",
    "\n",
    "        wandb.login()\n",
    "        init_w_and_b()\n",
    "\n",
    "    train_batch_iterator = get_batch_iterator(\"train\", hparams[\"batch_size\"])\n",
    "    test_batch_iterator = get_batch_iterator(\"test\", hparams[\"batch_size\"])\n",
    "    val_batch_iterator = get_batch_iterator(\"val\", hparams[\"batch_size\"])\n",
    "    all_iterators = [train_batch_iterator, test_batch_iterator, val_batch_iterator]\n",
    "\n",
    "    train_and_validation(hparams, all_iterators)\n",
    "\n",
    "    if WB:\n",
    "        wandb.finish()"
   ],
   "metadata": {
    "id": "6301OfyzcDL1",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:54:37.375754Z",
     "end_time": "2023-08-20T16:54:37.391861Z"
    }
   },
   "execution_count": 123,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "086wfzHecIAu",
    "outputId": "72f92418-0d9c-40d3-ddd3-4d5f45ab68bd",
    "ExecuteTime": {
     "start_time": "2023-08-20T16:53:32.690675Z",
     "end_time": "2023-08-20T16:54:07.966986Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [19:38<2:53:16, 57.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set: Average loss: 2.8706, Average WER: 1.0000\n",
      "\n",
      "Ground Truth -> Decoded Prediction\n",
      "c e d a r v i l l e -> \n",
      "p i t t s b u r g h -> \n",
      "rubout n i m n one -> \n",
      "three three one oh one eight eight -> \n",
      "m e l v i n -> \n",
      "one five two three two -> \n",
      "t r t f i seven -> \n",
      "m c k e e s r o c k s -> \n",
      "rubout n s v h t six forty nine -> \n",
      "enter five six eight -> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [1:30:06<48:01:13, 1041.41s/it]"
     ]
    }
   ]
  }
 ]
}
